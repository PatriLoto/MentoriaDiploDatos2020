{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practico 5 (parte 4)\n",
    "\n",
    "## Entrenar word embeddings\n",
    "\n",
    "## Importación de módulos y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclusion de librerias y módulos\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Usamos las stopwords definidas en nltk más algunas propias\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english') + [',', \"’\", '.', ':', '-', ';']\n",
    "\n",
    "# Algunas utilidades\n",
    "from utiles import print_some_info\n",
    "from utiles import convert_emojis\n",
    "from utiles import convert_emoticons\n",
    "\n",
    "# Nos permite convertir str a list\n",
    "from ast import literal_eval\n",
    "\n",
    "# Importamos wrod2vec de la lib gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Importamos logger para tener informacion de estado\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Colores\n",
    "BLUE   = '#5DADE2'\n",
    "RED    = '#ff7043'\n",
    "ORANGE = '#F5B041'\n",
    "GREEN  = '#58D68D'\n",
    "YELLOW = '#F4D03F'\n",
    "pltcolors = [BLUE, RED, ORANGE, GREEN, YELLOW]\n",
    "\n",
    "# Plot axes y legends parambs\n",
    "plt.rcParams[\"axes.labelweight\"]   = \"bold\"\n",
    "plt.rcParams[\"axes.titleweight\"]   = \"bold\"\n",
    "plt.rcParams[\"legend.shadow\"]      = True\n",
    "plt.rcParams[\"figure.titleweight\"] = \"bold\"\n",
    "\n",
    "data_dir = os.path.join('..', 'dataset')\n",
    "\n",
    "filename = 'dev_yup_messages_preprocessed.csv'\n",
    "SAVE_CURATED_DATASET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del archivo de mensajes\n",
    "Utilizamos unicamente el archivo de mensajes dado que vamos a entrenar un word embeding como word2vec. Entendemos que para el propósito del análisis y por que no estamos empleando ningún modelo de clasificación o regresión podemos usar el conjunto de datos completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curación evitada\n"
     ]
    }
   ],
   "source": [
    "if SAVE_CURATED_DATASET:\n",
    "    df = pd.read_csv(os.path.join(data_dir, filename))\n",
    "\n",
    "    print(f'El conjunto de datos utilizado es {filename}')\n",
    "    print_some_info(df)\n",
    "else:\n",
    "    print('Curación evitada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curacion del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El conjunto de datos posee 210242 filas y 3 columnas\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210242 entries, 0 to 210241\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   session_id  210242 non-null  int64 \n",
      " 1   sent_from   210242 non-null  object\n",
      " 2   text        210242 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "fn = os.path.join(data_dir, filename.replace('.csv','_curated.csv'))\n",
    "if SAVE_CURATED_DATASET:\n",
    "    #1. Tomamos solo las columnas que nos pueden servir. Esto es preliminar, podríamos tomar solo `text`\n",
    "    dfclean = df[['session_id', 'sent_from', 'text']]\n",
    "\n",
    "    #2. Tomamos solo las filas que sean tutor o student a partir de la columna `sent_from`\n",
    "    dfclean = dfclean[dfclean.sent_from.isin(['student', 'tutor'])]\n",
    "\n",
    "    #3. Convertimos a lista de strings el contenido de la columna text\n",
    "    dfclean['text'] = dfclean.text.apply(lambda x: literal_eval(x))\n",
    "\n",
    "    #4. Se sustituyen emojis por tokens \n",
    "    dfclean['text'] = dfclean.text.apply(lambda x: [convert_emojis(w) for w in x])\n",
    "\n",
    "    #5. Se sustituyen emoticones por palabras\n",
    "    ## No lo vamos a tratar por ahora por que requiere de un mejor tratamiento. \n",
    "    # Los parentesis, llaves y corchetes parece que el uso regular afecta al manejo del emoticon. \n",
    "    # dfclean['text'] = dfclean.text.apply(lambda x: [convert_emoticons(w) for w in x])\n",
    "\n",
    "    #6. Convernitimos a minúsculas para unificar el tratamiento\n",
    "    dfclean['text'] = dfclean.text.apply(lambda x: [w.lower() for w in x])\n",
    "\n",
    "    #7. Removemos las stopwords\n",
    "    dfclean['text'] = dfclean.text.apply(lambda x: [w for w in x if w not in stopwords])\n",
    "\n",
    "    dfclean.to_csv(fn, index=False)\n",
    "else:\n",
    "    #8. Se carga el archivo curado \n",
    "    dfclean = pd.read_csv(fn)\n",
    "    \n",
    "    #9. Convertimos a lista de strings el contenido de la columna text\n",
    "    dfclean['text'] = dfclean.text.apply(lambda x: literal_eval(x))\n",
    "\n",
    "print_some_info(dfclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-06 20:42:15,641 : INFO : collecting all words and their counts\n",
      "2020-10-06 20:42:15,644 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-06 20:42:15,689 : INFO : PROGRESS: at sentence #10000, processed 42888 words, keeping 3498 word types\n",
      "2020-10-06 20:42:15,714 : INFO : PROGRESS: at sentence #20000, processed 84921 words, keeping 5278 word types\n",
      "2020-10-06 20:42:15,743 : INFO : PROGRESS: at sentence #30000, processed 126737 words, keeping 6775 word types\n",
      "2020-10-06 20:42:15,773 : INFO : PROGRESS: at sentence #40000, processed 167356 words, keeping 8082 word types\n",
      "2020-10-06 20:42:15,808 : INFO : PROGRESS: at sentence #50000, processed 208696 words, keeping 9217 word types\n",
      "2020-10-06 20:42:15,828 : INFO : PROGRESS: at sentence #60000, processed 247775 words, keeping 10307 word types\n",
      "2020-10-06 20:42:15,847 : INFO : PROGRESS: at sentence #70000, processed 288680 words, keeping 11328 word types\n",
      "2020-10-06 20:42:15,874 : INFO : PROGRESS: at sentence #80000, processed 327855 words, keeping 12544 word types\n",
      "2020-10-06 20:42:15,894 : INFO : PROGRESS: at sentence #90000, processed 365169 words, keeping 13561 word types\n",
      "2020-10-06 20:42:15,915 : INFO : PROGRESS: at sentence #100000, processed 404264 words, keeping 14455 word types\n",
      "2020-10-06 20:42:15,940 : INFO : PROGRESS: at sentence #110000, processed 443711 words, keeping 15458 word types\n",
      "2020-10-06 20:42:15,959 : INFO : PROGRESS: at sentence #120000, processed 482818 words, keeping 16412 word types\n",
      "2020-10-06 20:42:15,982 : INFO : PROGRESS: at sentence #130000, processed 522083 words, keeping 17399 word types\n",
      "2020-10-06 20:42:16,017 : INFO : PROGRESS: at sentence #140000, processed 562129 words, keeping 18382 word types\n",
      "2020-10-06 20:42:16,037 : INFO : PROGRESS: at sentence #150000, processed 600320 words, keeping 19278 word types\n",
      "2020-10-06 20:42:16,070 : INFO : PROGRESS: at sentence #160000, processed 639050 words, keeping 20101 word types\n",
      "2020-10-06 20:42:16,095 : INFO : PROGRESS: at sentence #170000, processed 677385 words, keeping 20848 word types\n",
      "2020-10-06 20:42:16,116 : INFO : PROGRESS: at sentence #180000, processed 717710 words, keeping 21696 word types\n",
      "2020-10-06 20:42:16,133 : INFO : PROGRESS: at sentence #190000, processed 757131 words, keeping 22521 word types\n",
      "2020-10-06 20:42:16,153 : INFO : PROGRESS: at sentence #200000, processed 797496 words, keeping 23345 word types\n",
      "2020-10-06 20:42:16,174 : INFO : PROGRESS: at sentence #210000, processed 837252 words, keeping 24073 word types\n",
      "2020-10-06 20:42:16,175 : INFO : collected 24091 word types from a corpus of 838230 raw words and 210242 sentences\n",
      "2020-10-06 20:42:16,177 : INFO : Loading a fresh vocabulary\n",
      "2020-10-06 20:42:16,214 : INFO : effective_min_count=100 retains 838 unique words (3% of original 24091, drops 23253)\n",
      "2020-10-06 20:42:16,216 : INFO : effective_min_count=100 leaves 717087 word corpus (85% of original 838230, drops 121143)\n",
      "2020-10-06 20:42:16,227 : INFO : deleting the raw counts dictionary of 24091 items\n",
      "2020-10-06 20:42:16,235 : INFO : sample=0.001 downsamples 77 most-common words\n",
      "2020-10-06 20:42:16,237 : INFO : downsampling leaves estimated 494265 word corpus (68.9% of prior 717087)\n",
      "2020-10-06 20:42:16,252 : INFO : estimated required memory for 838 words and 300 dimensions: 2430200 bytes\n",
      "2020-10-06 20:42:16,253 : INFO : resetting layer weights\n",
      "2020-10-06 20:42:16,489 : INFO : training model with 4 workers on 838 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-10-06 20:42:17,511 : INFO : EPOCH 1 - PROGRESS: at 82.32% examples, 404062 words/s, in_qsize 7, out_qsize 0\n",
      "2020-10-06 20:42:17,671 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-10-06 20:42:17,684 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-06 20:42:17,687 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-06 20:42:17,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-06 20:42:17,704 : INFO : EPOCH - 1 : training on 838230 raw words (494333 effective words) took 1.2s, 411539 effective words/s\n",
      "2020-10-06 20:42:18,715 : INFO : EPOCH 2 - PROGRESS: at 74.91% examples, 371880 words/s, in_qsize 7, out_qsize 0\n",
      "2020-10-06 20:42:18,981 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-10-06 20:42:18,992 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-06 20:42:18,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-06 20:42:18,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-06 20:42:18,996 : INFO : EPOCH - 2 : training on 838230 raw words (494244 effective words) took 1.3s, 385577 effective words/s\n",
      "2020-10-06 20:42:20,028 : INFO : EPOCH 3 - PROGRESS: at 71.30% examples, 353354 words/s, in_qsize 6, out_qsize 1\n",
      "2020-10-06 20:42:20,292 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-10-06 20:42:20,322 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-06 20:42:20,333 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-06 20:42:20,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-06 20:42:20,346 : INFO : EPOCH - 3 : training on 838230 raw words (494775 effective words) took 1.3s, 373560 effective words/s\n",
      "2020-10-06 20:42:21,397 : INFO : EPOCH 4 - PROGRESS: at 76.22% examples, 372531 words/s, in_qsize 7, out_qsize 0\n",
      "2020-10-06 20:42:21,634 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-10-06 20:42:21,655 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-06 20:42:21,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-06 20:42:21,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-06 20:42:21,669 : INFO : EPOCH - 4 : training on 838230 raw words (494300 effective words) took 1.3s, 383891 effective words/s\n",
      "2020-10-06 20:42:22,698 : INFO : EPOCH 5 - PROGRESS: at 77.46% examples, 380365 words/s, in_qsize 7, out_qsize 0\n",
      "2020-10-06 20:42:22,940 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-10-06 20:42:22,953 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-06 20:42:22,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-06 20:42:22,983 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-06 20:42:22,984 : INFO : EPOCH - 5 : training on 838230 raw words (494519 effective words) took 1.3s, 381828 effective words/s\n",
      "2020-10-06 20:42:22,985 : INFO : training on a 4191150 raw words (2472171 effective words) took 6.5s, 380608 effective words/s\n",
      "2020-10-06 20:42:22,993 : INFO : saving Word2Vec object under 20201006-204215_model_300-5-100-1.bin, separately None\n",
      "2020-10-06 20:42:23,003 : INFO : not storing attribute vectors_norm\n",
      "2020-10-06 20:42:23,005 : INFO : not storing attribute cum_table\n",
      "2020-10-06 20:42:23,034 : INFO : saved 20201006-204215_model_300-5-100-1.bin\n"
     ]
    }
   ],
   "source": [
    "size = 100\n",
    "window = 5\n",
    "min_count = 1\n",
    "sg = 0\n",
    "\n",
    "params = f'{size}-{window}-{min_count}-{sg}'\n",
    "fnmodel = f'{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}_model_{params}.bin'\n",
    "\n",
    "model = Word2Vec(list(dfclean.text), size=size, window=window, min_count=min_count, sg=sg, compute_loss=True, workers=4)\n",
    "model.save(fnmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thank', 0.8510875701904297),\n",
       " ('appreciate', 0.6383005380630493),\n",
       " ('pleasure', 0.6031033992767334),\n",
       " ('glad', 0.5878739953041077),\n",
       " ('bye', 0.585172712802887),\n",
       " ('efforts', 0.5836899876594543),\n",
       " ('today', 0.5703210830688477),\n",
       " ('yay', 0.5505203008651733),\n",
       " ('course', 0.5434335470199585),\n",
       " ('night', 0.5270049571990967)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('thanks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3283660.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_latest_training_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('diplo': venv)",
   "language": "python",
   "name": "python37664bitdiplovenvc8f1cc3d26344ed08febef30f9915ee6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
