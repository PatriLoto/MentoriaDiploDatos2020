{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practico_3y4_punto_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7fp8NQEywxo",
        "colab_type": "text"
      },
      "source": [
        "###**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KdM25aVtlis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Librerías \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "#import pandas.util.testing as tm\n",
        "\n",
        "# Para gráficos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Para dividir el dataset en train  y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Para tratamiento de texto\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Para el cálculo de tf y tf–idf \n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Algoritmo del Árbol de Decisión\n",
        "from sklearn.tree import (DecisionTreeClassifier, plot_tree)\n",
        "\n",
        "# Para utilizar Naive-Bayes para la clasificación\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Para utilizar el algoritmo del gradiente descendiente\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Validación Cruzada \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Para calcular métricas\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, classification_report) \n",
        "\n",
        "# Clases\n",
        "classes = ['0 - Negativa', '1 - Positiva']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMigTytrqYEW",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2eef2a67-869a-4a9e-add3-a5d9c826d4c3"
      },
      "source": [
        "#lectura del csv desde colab\n",
        "from google.colab import files   # para poder leer archivos que están en mi pc\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da74e6af-2454-4b3f-9363-8d1744183ff2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da74e6af-2454-4b3f-9363-8d1744183ff2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving curated_data_para_nlp.csv to curated_data_para_nlp.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVEW_Reeu4XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LECTURA DESDE JUPYTER NOTEBOOK\n",
        "\n",
        "#filename = 'curated_data_para_nlp.csv'\n",
        "#datos_curados = pd.read_csv(os.path.join('..', 'dataset', filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgnkYkv-jdb2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **Carga de datos**\n",
        "\n",
        "El archivo **curated_data_para_nlp.csv** se genera a partir del archivo yup_messages_preprocessed.csv y datadump-20150801-20171219.csv y se cura para aplicar sobre el mismo técnicas de procesamiento del lenguaje natural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-8CJXZJpeTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "cc5a640e-80e6-4859-967a-9dc9cabe359b"
      },
      "source": [
        "datos_curados= pd.read_csv('curated_data_para_nlp.csv')\n",
        "print('Tamaño del dataset: \\n')\n",
        "display(datos_curados.shape)  # simil: len(datos_curados)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño del dataset: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(17429, 21)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlXvB-UdvnMW",
        "colab_type": "text"
      },
      "source": [
        "### **Observo las primeras filas.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGbLRxcuuZ23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "6a0b5f86-cae7-4480-8160-ef2799dea8ff"
      },
      "source": [
        "datos_curados['tokens'].head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ['<url>', 'Do', \"n't\", 'worry', ',', 'no', 'mi...\n",
              "1    ['Do', \"n't\", 'worry', ',', 'no', 'minutes', '...\n",
              "2    ['Do', \"n't\", 'worry', ',', 'no', 'minutes', '...\n",
              "3    ['Do', \"n't\", 'worry', ',', 'no', 'minutes', '...\n",
              "4    ['Hello', '', 'Jasmyn', '', ':)', 'Welcome', '...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfTV7xxZvxRT",
        "colab_type": "text"
      },
      "source": [
        "### **Observo las últimas filas.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijtpsuAixYbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5c010d92-0aa0-45c1-9c85-8e9b2901993b"
      },
      "source": [
        "datos_curados['tokens'].tail()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        ['<url>', 'Do', \"n't\", 'worry', ',', 'no', 'mi...\n",
              "1        ['Do', \"n't\", 'worry', ',', 'no', 'minutes', '...\n",
              "2        ['Do', \"n't\", 'worry', ',', 'no', 'minutes', '...\n",
              "3        ['Do', \"n't\", 'worry', ',', 'no', 'minutes', '...\n",
              "4        ['Hello', '', 'Jasmyn', '', ':)', 'Welcome', '...\n",
              "                               ...                        \n",
              "17424    ['<url>', 'Hi', 'Steven', ',', 'welcome', 'to'...\n",
              "17425    ['<url>', 'Hi', 'natalia', ',', 'welcome', 'to...\n",
              "17426    ['<url>', 'Hi', '!', 'My', 'name', 'is', 'M.',...\n",
              "17427    ['<url>', 'Thanks', 'for', 'signing', 'up', 'M...\n",
              "17428                                            ['<url>']\n",
              "Name: tokens, Length: 17429, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9npQWwEzvwf",
        "colab_type": "text"
      },
      "source": [
        "### **Selecciono del dataset datos_curados las columnas de interés:**\n",
        "\n",
        "- tokens: el texto de los diálogos.\n",
        "- student_rating_cat: columna calculada a partir de la calificación asignada por el alumno a la sesión: '0 - Negativa', '1 - Positiva'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SffGkvZWzRb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "45d565ce-0de1-4d97-afb0-f745904768c6"
      },
      "source": [
        "df_x=datos_curados['tokens']\n",
        "df_y=datos_curados['student_rating_cat'] #datos_curados.student_rating_cat \n",
        "print('Longitud de df_x:', len(df_x), ' y Longitud de df_y:', len(df_y))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud de df_x: 17429  y Longitud de df_y: 17429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpNVjkU8wYf-",
        "colab_type": "text"
      },
      "source": [
        "### **División y normalización de los datos**\n",
        "\n",
        "1. El conjunto de datos es dividido en datos de entrada o alimentación y en la referencia o target al cual debe apuntar el clasificador al momento de predecir.\n",
        "\n",
        "1. Se divide nuevamente al conjunto de datos en datos de entrenamiento o train y datos de evaluación o test, cada uno de ellos con su correspondiente referencia o target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O76sbPMKt366",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "54ea4c16-586c-4f66-84e5-e657a28d2332"
      },
      "source": [
        "# División entre instancias y etiquetas\n",
        "X, y = df_x, df_y       #datos_curados['tokens'], datos_curados.student_rating_cat   \n",
        "\n",
        "# división entre entrenamiento y evaluación\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "print('La Longitud del conj. de datos de train es', len(X_train), 'y la longitud del conj. de datos de test es', len(X_test))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La Longitud del conj. de datos de train es 13943 y la longitud del conj. de datos de test es 3486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yf7z0JpRjN_",
        "colab_type": "text"
      },
      "source": [
        "## **Bolsa de palabras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qeGRjw3ltuh",
        "colab_type": "text"
      },
      "source": [
        "### **Vectorizamos el texto con el método CountVectorizer()** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ6K_ULg4oy-",
        "colab_type": "text"
      },
      "source": [
        "### Utilizando el método **CountVectorizer** convertimos el texto de **X_train** en vectores numéricos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S8a7226kIC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a64b5ac8-6a36-4e69-fc75-7719c1bedabb"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# trabajamos con CountVectorizer sin parámetros por defecto\n",
        "vectorizer = CountVectorizer()\n",
        "x_traincv= vectorizer.fit_transform(X_train)          #Learn the vocabulary dictionary and return document-term matrix.\n",
        "\n",
        "# ¿cuál es la dimensión de la matriz dispersa?\n",
        "print('Dimensión de la matriz dispersa \\n.')\n",
        "x_traincv "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensión de la matriz dispersa \n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<13943x33560 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2422063 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhkIilla5xfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "24a7b0ea-26ce-4f1c-9de0-d6a0936896a2"
      },
      "source": [
        "a=x_traincv.toarray()\n",
        "a[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDCosc8u6R0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "a86601f3-f685-4350-92df-dc35fcf7209d"
      },
      "source": [
        "x_traincv.inverse_transform(a[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-db98feaf96f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_traincv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: inverse_transform not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDcxHUJkD-DV",
        "colab_type": "text"
      },
      "source": [
        "### **Valores de la matriz dispersa**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsV-NETRv9yD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "6cdb2eec-1acc-4f32-bc67-81525c33eec2"
      },
      "source": [
        "# imprimimos lo valores de la matriz dispersa\n",
        "print(x_traincv.toarray())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-47abd5a78e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# imprimimos lo valores de la matriz dispersa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_traincv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_traincv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR5ib8DpCeEf",
        "colab_type": "text"
      },
      "source": [
        "### **Matriz dispersa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UON9P_dLCLmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7e321632-d93c-4eaa-fae5-c8bcb198603e"
      },
      "source": [
        "#print(x_traincv.get_feature_names())\n",
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-681a01383216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print(x_traincv.get_feature_names())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_traincv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: get_feature_names not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi1eNFTi44yz",
        "colab_type": "text"
      },
      "source": [
        "### Utilizando el método **CountVectorizer** convertiremos el texto de **X_test** en vectores numéricos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ObsFZK44S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# trabajamos con CountVectorizer sin parámetros por defecto\n",
        "vectorizer2 = CountVectorizer()\n",
        "x_testcv= vectorizer2.fit_transform(X_test)          #Learn the vocabulary dictionary and return document-term matrix.\n",
        "\n",
        "# ¿cuál es la dimensión de la matriz dispersa?\n",
        "print('Dimensión de la matriz dispersa \\n.')\n",
        "x_testcv "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChDmX42Y9WgU",
        "colab_type": "text"
      },
      "source": [
        "### **Valores de la matriz dispersa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biKPZFQ99b40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimimos lo valores de la matriz dispersa\n",
        "print(x_testcv.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8JFAmmNmBNu",
        "colab_type": "text"
      },
      "source": [
        "### **Cálculo de tf y tf–idf para unigramas**\n",
        "\n",
        "El **tf** es la frecuencia de términos en un documento y el **idf** es la frecuencia inversa de un término en el conjunto de documentos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EKaUEXkjHvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3a1de1fe-6966-4f0e-c985-712d71313977"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_tfidf = tfidf_transformer.fit_transform(unigrama_vectorizer)\n",
        "#print('Tamaño de la matriz',X_tfidf.shape)\n",
        "print(\"Longitud del vector:\", len(X_tfidf.toarray()[0]))\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud del vector: 37727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FLxnY5tcgXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "76bf9849-8392-4d95-ca29-e02066f4178a"
      },
      "source": [
        " print(len(X_tfidf.toarray()[0]))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yQ9fzx-yeeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "7afce65f-31c9-4261-945e-c02472e69d9d"
      },
      "source": [
        "print('Valores de la matriz con el cálculo de tf-idf \\n')\n",
        "print(X_tfidf.toarray())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valores de la matriz con el cálculo de tf-idf \n",
            "\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.13823712 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1KNUe4Ew4RD",
        "colab_type": "text"
      },
      "source": [
        "### **Trabajamos con bigramas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsz5uPzow36C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "54460143-cd3e-4fed-b2d0-1c1449ab6f33"
      },
      "source": [
        "bigrama_vectorizer = CountVectorizer(ngram_range=(2, 2), min_df=1)  # dejamos de lado las palabras de frecuencia 1\n",
        "X_2 = bigrama_vectorizer.fit_transform(datos_curados['tokens'])\n",
        "# ¿cuál es la dimensión de la matriz dispersa?\n",
        "print('Dimensión de la matriz dispersa \\n.')\n",
        "X_2  #o X.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0euuAWUI5pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(bigrama_vectorizer.get_feature_names())    #Array mapping from feature integer indices to feature name.\n",
        "print('Valores del vector')\n",
        "print(X_2.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEFVXJ1nxoI2",
        "colab_type": "text"
      },
      "source": [
        "###**Cálculo de tf y tf–idf para bigramas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irYm3nvnzAmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_2_tfidf = tfidf_transformer.fit_transform(X_2)\n",
        "print('Tamaño de la matriz',X_2_tfidf.shape)\n",
        "X_2_tfidf.shape\n",
        "\n",
        "print(\"Longitud del vector:\", len(X_2_tfidf.toarray()[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_MofCF7QgI",
        "colab_type": "text"
      },
      "source": [
        "### **Otra opción es utilizar HashingVectorizer**\n",
        "\n",
        "Una opción a la utilización de CountVectorizer es utilizar el método 'HashingVectorizer' ya que utiliza menos menoria y es escalable a grandes conjuntos de datos. Usa un truco de hash para encontrar el nombre de la cadena del token para presentar la asignación de índices. Esto significa que usa muy poca memoria y escala a grandes conjuntos de datos, ya que no necesita almacenar todo el vocabulario y es más rápido de seleccionar y ajustar, ya que no hay ningún estado. Sin embargo, no hay transformación inversa (de vector a texto), puede haber colisiones y no hay ponderación de frecuencia de documento inversa.\n",
        "\n",
        " Referencia: https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/ch04.html#ATAP04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spOtm3dC-r1v",
        "colab_type": "text"
      },
      "source": [
        "###**Vectorizamos el texto con el método HashingVectorizer()**\n",
        "\n",
        "### Utilizando el método HashingVectorizer() convertiremos el texto de X_train en vectores numéricos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMV8dX9C7PPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5dd96974-190f-45e1-fb4d-87ddc463ec6e"
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "vectorizer3 = HashingVectorizer(n_features=2**4)\n",
        "x_trainhv = vectorizer3.fit_transform(X_train)\n",
        "print('Dimensión de la matriz dispersa \\n.')\n",
        "print(X_train.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensión de la matriz dispersa \n",
            ".\n",
            "(17429, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sexlck_U-s9s",
        "colab_type": "text"
      },
      "source": [
        "### Utilizando el método HashingVectorizer() convertiremos el texto de X_test en vectores numéricos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VxQYhM1-tco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer3 = HashingVectorizer(n_features=2**4)\n",
        "x_testhv = vectorizer3.fit_transform(X_test)\n",
        "print('Dimensión de la matriz dispersa \\n.')\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SYmBI8Ho0Nz",
        "colab_type": "text"
      },
      "source": [
        "## **Árboles de Decisión¶**\n",
        "Se crea el objeto del modelo y se imprimen los parametros por defecto que posee el modelo. Se fija la semilla para hacer reproducible el experimento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Woi0KQbA9Ky",
        "colab_type": "text"
      },
      "source": [
        "### Arboles de decisión con countVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz6BFWI3ozbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arbol_decision = DecisionTreeClassifier(random_state = 42) # para que coincida con el random_state elegido para SGD\n",
        "\n",
        "print('Parámetros utilizados: \\n', np.array(list(arbol_decision.get_params(deep=False).items())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zsb59tnBe4x",
        "colab_type": "text"
      },
      "source": [
        "### **Entrenamiento**\n",
        "\n",
        "El modelo es entrenado con los parámetros que posee la implementación por defecto, dicho roceso consume el conjunto de datos de entrenamiento y su correspondiente referencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82I5mdScBZjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arbol_decision.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3W_Q7ndBZK5",
        "colab_type": "text"
      },
      "source": [
        "### **Predicción con el conjuto de datos de entrenamiento y test¶**\n",
        "\n",
        "\n",
        "Se lleva a cabo el proceso de predicción tomando como entrada al modelo\n",
        "\n",
        "- El conjunto de datos de entrenamiento\n",
        "- El conjunto de datos de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sGz7nZhCNL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1. Predicción con el conjunto de datos de entrenamiento\n",
        "y_train_pred_arbolD = arbol_decision.predict(X_train)\n",
        "y_train_pred_arbolDp = arbol_decision.predict_proba(X_train)\n",
        "\n",
        "#1. Predicción con el conjunto de datos de test\n",
        "y_test_pred_arbolD  = arbol_decision.predict(X_test)\n",
        "y_test_pred_arbolDp = arbol_decision.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcnDTiHqCoUV",
        "colab_type": "text"
      },
      "source": [
        "### **Verificamos la accuracy obtenida.**\n",
        "\n",
        "### Accuracy con train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrW3Ya05CnCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('Accuracy: %d ' % ((np.sum(y_train == y_train_pred_arbolD))/float(y_train.size)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaDZT-MbC7YD",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy con test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21r_GzmDJCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('Accuracy: %d ' % ((np.sum(y_test == y_test_pred_arbolD))/float(y_test.size)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L1CEf_8DWWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Profundidad máxima del árbol:', arbol_decision.get_depth())\n",
        "print('Cantidad máxima de hojas:', arbol_decision.get_n_leaves())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8AF78Dao1vS",
        "colab_type": "text"
      },
      "source": [
        "### Arboles de decisión con HashingVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOZ_j89wo1BW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arbol_decision = DecisionTreeClassifier(random_state = 42) # para que coincida con el random_state elegido para SGD\n",
        "\n",
        "print('Parámetros utilizados: \\n', np.array(list(arbol_decision.get_params(deep=False).items())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE6eJuEBEOV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arbol_decision.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01iFKdolE6h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1. Predicción con el conjunto de datos de entrenamiento\n",
        "y_train_pred_arbolD = arbol_decision.predict(X_train)\n",
        "y_train_pred_arbolDp = arbol_decision.predict_proba(X_train)\n",
        "\n",
        "#1. Predicción con el conjunto de datos de test\n",
        "y_test_pred_arbolD  = arbol_decision.predict(X_test)\n",
        "y_test_pred_arbolDp = arbol_decision.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADFPDzUgE-hN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy con train\n",
        "\n",
        "print ('Accuracy con train: %d ' % ((np.sum(y_train == y_train_pred_arbolD))/float(y_train.size)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pSSYgcAFDkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy con test\n",
        "print ('Accuracy con test: %d ' % ((np.sum(y_test == y_test_pred_arbolD))/float(y_test.size)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhQRQnVvEA2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Profundidad máxima del árbol:', arbol_decision.get_depth())\n",
        "print('Cantidad máxima de hojas:', arbol_decision.get_n_leaves())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjtE_U7rEAlp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxB1q9vazTj4",
        "colab_type": "text"
      },
      "source": [
        "### **Hiperparámetros para utilizar con CountVectorizer**\n",
        "\n",
        "### Con el objetivo de visualizar lo que hace CountVectorizer exploraremos sus hiperparámetros **min_df, max_df** y **ngram-range.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bawsFEVS0kG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# definimos los parámetros\n",
        "param_grid = {\n",
        "  'analyzer': ['word'],\n",
        "  'ngram_range': np.arange(1,4),\n",
        "  'max_df': [0.0, 1.0],    #cuando trabajamos con flotante nos referimos a la proporción máxima de aparición/frecuencia de un determinado término \n",
        "  'min_df':[0.0, 1.0]}\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udt2M0lD3Sgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "a8ff3d5f-0706-4f7c-b782-007bebd128e1"
      },
      "source": [
        "# aplicamos gridsearchCV con CountVectorizer sobre unigramas y tuneo de parámetros\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='English')\n",
        "grid_search = GridSearchCV(vectorizer, param_grid, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-a50078cdafb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'English'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0;32m--> 629\u001b[0;31m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    471\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    472\u001b[0m                                                           str):\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                 % estimator)\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n",
            "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n                ngram_range=(1, 1), preprocessor=None, stop_words='English',\n                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                tokenizer=None, vocabulary=None) does not."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvrUQ8fVkvl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK: print the mean and std for each candidate along with the parameter\n",
        "    # settings for all the candidates explored by grid search.\n",
        "n_candidates = len(grid_search.cv_results_['params'])\n",
        "for i in range(n_candidates):\n",
        "    print(i, 'params - %s; mean - %0.2f; std - %0.2f'\n",
        "            % (grid_search.cv_results_['params'][i],\n",
        "            grid_search.cv_results_['mean_test_score'][i],\n",
        "            grid_search.cv_results_['std_test_score'][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jewUG6qOk8p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # TASK: Predict the outcome on the testing set and store it in a variable\n",
        "    # named y_predicted\n",
        "    y_predicted = grid_search.predict(X_test)\n",
        "\n",
        "    # Print the classification report\n",
        "    print(metrics.classification_report(y_test, y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5-m1bSxexK",
        "colab_type": "text"
      },
      "source": [
        "### Otra opción es utilizar el método TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-4savzOxCV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# otra opción es utilizar el método TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='English')\n",
        "grid_search = GridSearchCV(vectorizer, param_grid, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niDsEd14RatM",
        "colab_type": "text"
      },
      "source": [
        "### Es decir, si min_df es 0.005, todas las palabras que representen menos de un 0,5% de las palabras totales serán descartadas. Por el otro lado, si max_df es 0.35, todas las palabras que representen más de un 35% del total de palabras serán descartadas. Visualizar las palabras que serían descartadas dentro de este rango y describir cómo son."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "523PDohiSK0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "aed3c01f-685e-43e0-d343-ba5a38fab518"
      },
      "source": [
        "vectorizer_min = CountVectorizer(min_df= 0.0, max_df= 0.005)\n",
        "X_4 = vectorizer_min.fit_transform(datos_curados['tokens'])  #Learn the vocabulary dictionary and return document-term matrix.\n",
        "# ¿cuál es la dimensión de la matriz dispersa?\n",
        "print('Dimensión de la matriz dispersa \\n.')\n",
        "X_4  #o X.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensión de la matriz dispersa \n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<17429x35766 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 175718 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGycYDGgWK0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d980d522-0253-476c-e303-cb6538e0de21"
      },
      "source": [
        "vectorizer_max = CountVectorizer(min_df= 0.35)\n",
        "#vectorizer = CountVectorizer(min_df= 0.005, max_df= 0.35)\n",
        "X_5 = vectorizer_max.fit_transform(datos_curados['tokens'])   #Learn the vocabulary dictionary and return document-term matrix.\n",
        "# ¿cuál es la dimensión de la matriz dispersa?\n",
        "print('Dimensión de la matriz dispersa \\n.')\n",
        "X_5 #o X.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensión de la matriz dispersa \n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<17429x128 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1408383 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grkVpGnHwiUj",
        "colab_type": "text"
      },
      "source": [
        "EXTRAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hISsO0Xw4tbG",
        "colab_type": "text"
      },
      "source": [
        "### **Naive-Bayes**\n",
        "Baseline con Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEaNLotBntXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "778b4e64-6eb1-4948-9f9a-3564e4a3571c"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#clf = MultinomialNB().fit(X_train_tfidf, datos_curados.student_rating_cat)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6], fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQmX4FMUcUh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = text_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1V1pMK2GMHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1GOh_UTIz8c",
        "colab_type": "text"
      },
      "source": [
        "### **Referencias**\n",
        "\n",
        "[Método CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)\n",
        "\n",
        "[Método TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)\n",
        "\n",
        "Equivalent to CountVectorizer followed by TfidfTransformer.Ejemplo con parámetros: TfidfVectorizer(min_df=3, max_df=0.95)\n",
        "\n",
        "[Método TfidfTransformer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)\n",
        "\n",
        "[Repo sobre Applied Text Analysis with Python](https://github.com/foxbook/atap\n",
        ")\n",
        "\n",
        "Vectorización:\n",
        "\n",
        "https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/ch04.html#ATAP04\n",
        "\n",
        "https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/\n",
        " https://github.com/foxbook/atap/blob/master/snippets/ch04/vectorization.py\n",
        "\n",
        "[Ejemplo de aplicación de CountVectorizer()](https://github.com/shreyans29/thesemicolon/blob/master/Text%20Analytics%20CV.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}