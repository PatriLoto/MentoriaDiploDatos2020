{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python37664bitdiplovenvc8f1cc3d26344ed08febef30f9915ee6",
      "display_name": "Python 3.7.6 64-bit ('diplo': venv)"
    },
    "colab": {
      "name": "Practico_3y4_part_6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgMYMTW2SL5Y"
      },
      "source": [
        "# Practico 3 y 4 (parte 6)\n",
        "\n",
        "## Ablación de datos\n",
        "\n",
        "A medida que los sistemas de aprendizaje automático se utilizan en un número cada vez mayor de aplicaciones, desde el análisis de datos sensoriales de satélites y el análisis de la atención de la salud hasta los asistentes virtuales inteligentes y los coches autoconductores, también se están volviendo cada vez más complejos. Esto significa que se necesita más tiempo y recursos de computación para entrenar los modelos y el número de opciones de diseño e hiperparámetros también aumentará. Debido a esta complejidad, suele ser difícil explicar el efecto de cada elección de diseño o componente del sistema de aprendizaje automático sobre su rendimiento. En el contexto del aprendizaje por máquina, podemos definir el estudio de la ablación como \"un examen científico de un sistema de aprendizaje por máquina mediante la eliminación de sus componentes básicos para comprender sus efectos sobre su rendimiento general\". Las características del conjunto de datos y los componentes del modelo son ejemplos notables de estos bloques de construcción (por lo tanto, utilizamos sus correspondientes términos de ablación de características y ablación de modelos), pero cualquier elección de diseño o módulo del sistema puede incluirse en un estudio de ablación. Sin embargo, los estudios de ablación no forman parte actualmente de la práctica estándar de aprendizaje de máquinas. Una de las razones fundamentales de ello es el hecho de que actualmente la realización de un estudio de ablación requiere importantes modificaciones del código, así como recursos informáticos y de tiempo adicionales. Por otra parte, la experimentación con un sistema de aprendizaje automático es un proceso iterativo que consiste en varios ensayos.\n",
        "\n",
        "* [Ablation Programming for Machine Learning](http://www.diva-portal.org/smash/record.jsf?aq2=%5B%5B%5D%5D&c=1&af=%5B%5D&searchType=SIMPLE&sortOrder2=title_sort_asc&query=sina%2Bsheikholeslami&language=en&pid=diva2%3A1349978&aq=%5B%5B%5D%5D&sf=all&aqe=%5B%5D&sortOrder=author_sort_asc&onlyFullText=false&noOfRows=50&dswid=-716)\n",
        "* [In the context of deep learning, what is an ablation study?](https://www.quora.com/In-the-context-of-deep-learning-what-is-an-ablation-study)\n",
        "\n",
        "## Importación de módulos y librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYgjRo4wSL5Z"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from ast import literal_eval\n",
        "\n",
        "from utiles import student_rating_category\n",
        "from utiles import ablation\n",
        "\n",
        "data_dir = os.path.join('..', 'dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iobHiW2SSL5e"
      },
      "source": [
        "## Procesamiento del data frame de metadata `md_df`\n",
        "\n",
        "1. Se carga el conjunto de datos correspondiente a la metadata\n",
        "2. Se conservan las columnas `session_id` y `student_rating` con el objetivo de convertir la variable `student_rating` en una variable categórica para indicar el éxito o fracaso de sesion.\n",
        "3. Se eliminan del data frame las filas cuya entrada en la columna `student_rating` no contengan datos.\n",
        "4. Se convierte a variable categórica la variable `student_rating` mediante el uso de la funcion auxiliar `student_rating_category`.\n",
        "5. Se remueven las filas cuya entrada en la columna `student_rating` contenga la plabra 'neutra'. De este modo la variable categórica es binaria, indicando con '1' éxito y con '0' fracaso.\n",
        "6. Se imprime información de estado del data frame.\n",
        "\n",
        "Finalmente, obtendremos un data frame con la variable categórica binaria `student_rating` y su correspondiente número de sesión `session_id` que permitirá asociar el resultado de la sesión al conjunto de datos correspondiente a los diálogos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "eB9i_XScSL5f",
        "outputId": "9370a2c4-7cae-4dbc-9b3c-7d2c5d5f5a0a"
      },
      "source": [
        "#1. Dataset de metadata\n",
        "md_data_file_name = 'datadump-20150801-20171219.csv'\n",
        "md_full_data_file_name = os.path.join(data_dir, md_data_file_name)\n",
        "md_df = pd.read_csv(md_full_data_file_name, low_memory=False)\n",
        "\n",
        "#2. Selección de columnas\n",
        "md_df.columns = [column.strip() for column in md_df.columns]\n",
        "md_df = md_df[['session_id','student_rating']]\n",
        "\n",
        "#3. Eliminamos las filas nulas\n",
        "md_df = md_df.dropna(subset=['student_rating'])\n",
        "\n",
        "#4. Categorización de la variable numérica\n",
        "md_df['student_rating'] = md_df.student_rating.apply(student_rating_category)\n",
        "\n",
        "#5. Remoción de las filas con calificación neutra\n",
        "md_df = md_df.loc[md_df.student_rating != 'neutra'].astype(int)\n",
        "\n",
        "#6. Información del data frame resultante con la categorizacion de las sesiones\n",
        "md_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 46164 entries, 0 to 63264\n",
            "Data columns (total 2 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   session_id      46164 non-null  int64\n",
            " 1   student_rating  46164 non-null  int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 1.1 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irVrwJyFSL5k"
      },
      "source": [
        "## Carga de los conjunto de datos de mensaje\n",
        "\n",
        "1. Se carga el conjunto de datos correspondiente a los mensajes entre tutor y estudiante.\n",
        "2. Conservamos las columnas que son necesarias para el entrenamiento del modelo. En este caso `text` cotiene el texto de interés, `sent_from` identifica el originante del mensaje a los fines de analizar su impacto mediante ablación de datos y `session_id` permitirá realizar la composición de ambos datasets.\n",
        "3. Se remueven todas las filas que no contengan mensajes del estudiante o tutor.\n",
        "4. Se convierte la representacion textual de las listas en listas de python propiamente.\n",
        "5. Se imprime información de estado del data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "kKEOR2GqSL5k",
        "outputId": "d2ec8b11-8f15-4268-c53b-d55715b83413"
      },
      "source": [
        "#1. Dataset de mensajes\n",
        "msg_file_name = 'yup_messages_preprocessed.csv'\n",
        "msg_full_file_name = os.path.join(data_dir, msg_file_name)\n",
        "msg_df = pd.read_csv(msg_full_file_name)\n",
        "\n",
        "#2. Selección de columnas\n",
        "msg_df = msg_df[['session_id', 'sent_from', 'text']]\n",
        "\n",
        "#3. Tomamos solo las filas con contenido del tutor o el estudiante\n",
        "msg_df = msg_df[msg_df.sent_from.isin(['student','tutor'])]\n",
        "\n",
        "#4. Convertimos la representacion en str de las listas en listas propiamente\n",
        "msg_df['text'] = msg_df.text.apply(lambda x: literal_eval(x))\n",
        "\n",
        "#5. Información de estado del data frame\n",
        "msg_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1411477 entries, 0 to 1574068\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count    Dtype \n",
            "---  ------      --------------    ----- \n",
            " 0   session_id  1411477 non-null  int64 \n",
            " 1   sent_from   1411477 non-null  object\n",
            " 2   text        1411477 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 43.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkhqRuVtSL5o"
      },
      "source": [
        "## Casos de ablación\n",
        "\n",
        "Tomaremos el 20 %, 40 %, 60 %, 80 % y el 100 % de los turnos iniciando desde el final de la conversación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzFde3lJSL5o"
      },
      "source": [
        "tokeep_list = [0.2, 0.4 , 0.6, 0.8, 1.0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75mX6CvdSL5s"
      },
      "source": [
        "### Estudiantes y tutores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "7Aml9tbLSL5t"
      },
      "source": [
        "for tokeep in tokeep_list:\n",
        "    df = ablation(df=msg_df, tokeep=tokeep)\n",
        "    df = df.groupby('session_id').sum()\n",
        "    df = df.drop(columns='sent_from')\n",
        "    df = df.reset_index()\n",
        "    df = pd.merge(df, md_df, how='left', on=['session_id'])\n",
        "    df = df.dropna(subset=['student_rating'])\n",
        "    df['student_rating'] = df.student_rating.astype(int)\n",
        "\n",
        "    pathdf = os.path.join(data_dir, 'ablations', f'yup_messages_ablated_{tokeep:05.2f}_students_tutors.csv')\n",
        "    df.to_csv(pathdf, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdW2TPZ-SL5w"
      },
      "source": [
        "### Estudiantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ka7bBrYeSL5x"
      },
      "source": [
        "for tokeep in tokeep_list:\n",
        "    df = ablation(df=msg_df[msg_df.sent_from=='student'], tokeep=tokeep)\n",
        "    df = df.groupby('session_id').sum()\n",
        "    df = df.drop(columns='sent_from')\n",
        "    df = df.reset_index()\n",
        "    df = pd.merge(df, md_df, how='left', on=['session_id'])\n",
        "    df = df.dropna(subset=['student_rating'])\n",
        "    df['student_rating'] = df.student_rating.astype(int)\n",
        "\n",
        "    pathdf = os.path.join(data_dir, 'ablations', f'yup_messages_ablated_{tokeep:05.2f}_students.csv')\n",
        "    df.to_csv(pathdf, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wUlPpovSL51"
      },
      "source": [
        "### Tutores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH9C0H-_SL51"
      },
      "source": [
        "for tokeep in tokeep_list:\n",
        "    df = ablation(df=msg_df[msg_df.sent_from=='tutor'], tokeep=tokeep)\n",
        "    df = df.groupby('session_id').sum()\n",
        "    df = df.drop(columns='sent_from')\n",
        "    df = df.reset_index()\n",
        "    df = pd.merge(df, md_df, how='left', on=['session_id'])\n",
        "    df = df.dropna(subset=['student_rating'])\n",
        "    df['student_rating'] = df.student_rating.astype(int)\n",
        "\n",
        "    pathdf = os.path.join(data_dir, 'ablations', f'yup_messages_ablated_{tokeep:05.2f}_tutors.csv')\n",
        "    df.to_csv(pathdf, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_HeHtFgYrXW"
      },
      "source": [
        "## Evaluación de desempeño de los clasificadores utilizados en el práctico anterior: SGD, DT y Naive-Bayes.\n",
        "\n",
        "\n",
        "Luego de finalizado el proceso de ablación anteriormente detallado, continuamos con la evaluación de desempeño de tres clasificadores Stochastic Gradient Descent, Árbol de Decisiones y Multinomial Naive Bayes (previa aplicación de la técnica de ablación). A continuación se detallan los clasificadores analizados en la parte 8 del presente práctico:\n",
        "\n",
        "* en la [Parte 8a](https://github.com/PatriLoto/MentoriaDiploDatos2020/blob/master/Practico_3y4_part_8a.ipynb) se analiza el desempeño del Clasificador Stochastic Gradient Descent utilizando vectorización de diálogos, \n",
        "\n",
        "* en la [Parte 8b](https://github.com/PatriLoto/MentoriaDiploDatos2020/blob/master/Practico_3y4_part_8b.ipynb) se analiza el desempeño del Clasificador Árbol de Decisiones utilizando vectorización de diálogos,\n",
        "\n",
        "* en la [Parte 8c](https://github.com/PatriLoto/MentoriaDiploDatos2020/blob/master/Practico_3y4_part_8c.ipynb) se analiza el desempeño de Clasificador Multinomial Naive Bayes utilizando vectorización de diálogos.\n"
      ]
    }
  ]
}