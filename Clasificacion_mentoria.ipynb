{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificacion_mentoria.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KdM25aVtlis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "278227dd-85f4-4686-a429-5cdbaa860620"
      },
      "source": [
        "#Librerías \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.util.testing as tm\n",
        "# Para gráficos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from seaborn import heatmap\n",
        "from scipy import stats\n",
        "\n",
        "# Para dividir el dataset en train  y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Algoritmo del Gradiente Descendente\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Algoritmo del Árbol de Decisión\n",
        "from sklearn.tree import (DecisionTreeClassifier, plot_tree)\n",
        "\n",
        "# Validación Cruzada \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Para calcular métricas\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, confusion_matrix, classification_report,\n",
        "                            roc_curve, roc_auc_score, precision_recall_curve)\n",
        "\n",
        "# Para la Normalización cuando utilizamos SGDC\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tFFV_2ADSIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se ejecuta solo una vez\n",
        "#!pip install -U -q PyDrive\n",
        "\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_RIkm0YDXHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se ejecuta solo una vez\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9-Ap157D6di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://drive.google.com/file/d/1U4EOSlA58zqdEF9t-ztyGuUkvhfAwMtg/view?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGodZXcJpiJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1U4EOSlA58zqdEF9t-ztyGuUkvhfAwMtg'}) # reemplazar con el id del archivo al cual queres acceder, el id \n",
        "# lo sacas del link que te genera drive al compartir dicho documento\n",
        "downloaded.GetContentFile('train_curated_data.csv') "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-8CJXZJpeTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "datos_curados= pd.read_csv('train_curated_data.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxocXhBotA22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "fd914841-2abf-4d8e-d9b7-dce30ad29325"
      },
      "source": [
        "datos_curados.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tutor_id</th>\n",
              "      <th>tutor_age</th>\n",
              "      <th>session_tag_no_material</th>\n",
              "      <th>session_tag_student_left</th>\n",
              "      <th>session_tag_student_not_engaging</th>\n",
              "      <th>student_complained</th>\n",
              "      <th>student_complaint_clarity</th>\n",
              "      <th>student_complaint_speed</th>\n",
              "      <th>student_complaint_subject</th>\n",
              "      <th>student_complaint_other</th>\n",
              "      <th>session_tag_cheating</th>\n",
              "      <th>session_tag_inappropriate</th>\n",
              "      <th>session_tag_other_subject</th>\n",
              "      <th>avg_words_tutor</th>\n",
              "      <th>n_words_tutor</th>\n",
              "      <th>n_msg_tutor</th>\n",
              "      <th>avg_words_student</th>\n",
              "      <th>n_words_student</th>\n",
              "      <th>n_msg_student</th>\n",
              "      <th>student_rating_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.0</td>\n",
              "      <td>12165.0</td>\n",
              "      <td>12165.0</td>\n",
              "      <td>12165.0</td>\n",
              "      <td>12165.0</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "      <td>12165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>134474.392355</td>\n",
              "      <td>37.157254</td>\n",
              "      <td>0.018989</td>\n",
              "      <td>0.098726</td>\n",
              "      <td>0.015701</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011591</td>\n",
              "      <td>0.018660</td>\n",
              "      <td>0.010604</td>\n",
              "      <td>11.531647</td>\n",
              "      <td>428.854912</td>\n",
              "      <td>41.740485</td>\n",
              "      <td>4.068250</td>\n",
              "      <td>128.564406</td>\n",
              "      <td>30.598849</td>\n",
              "      <td>0.793342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>149074.197863</td>\n",
              "      <td>13.596913</td>\n",
              "      <td>0.136491</td>\n",
              "      <td>0.298306</td>\n",
              "      <td>0.124320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.107038</td>\n",
              "      <td>0.135327</td>\n",
              "      <td>0.102433</td>\n",
              "      <td>4.726268</td>\n",
              "      <td>467.544415</td>\n",
              "      <td>48.375324</td>\n",
              "      <td>2.205319</td>\n",
              "      <td>146.824769</td>\n",
              "      <td>32.579090</td>\n",
              "      <td>0.404925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>34864.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.622642</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>2.762376</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>44809.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.580645</td>\n",
              "      <td>287.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>3.766355</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>279250.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.448276</td>\n",
              "      <td>567.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>4.972973</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>510148.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5917.000000</td>\n",
              "      <td>645.000000</td>\n",
              "      <td>125.750000</td>\n",
              "      <td>1933.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            tutor_id     tutor_age  ...  n_msg_student  student_rating_cat\n",
              "count   12165.000000  12165.000000  ...   12165.000000        12165.000000\n",
              "mean   134474.392355     37.157254  ...      30.598849            0.793342\n",
              "std    149074.197863     13.596913  ...      32.579090            0.404925\n",
              "min         6.000000     15.000000  ...       0.000000            0.000000\n",
              "25%     34864.000000     23.000000  ...      10.000000            1.000000\n",
              "50%     44809.000000     33.000000  ...      21.000000            1.000000\n",
              "75%    279250.000000     52.000000  ...      39.000000            1.000000\n",
              "max    510148.000000     63.000000  ...     418.000000            1.000000\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8zMxe_ptOnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "ba4423de-577d-49c5-a790-5a2e7e066d57"
      },
      "source": [
        "datos_curados.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tutor_id</th>\n",
              "      <th>tutor_age</th>\n",
              "      <th>session_tag_no_material</th>\n",
              "      <th>session_tag_student_left</th>\n",
              "      <th>session_tag_student_not_engaging</th>\n",
              "      <th>student_complained</th>\n",
              "      <th>student_complaint_clarity</th>\n",
              "      <th>student_complaint_speed</th>\n",
              "      <th>student_complaint_subject</th>\n",
              "      <th>student_complaint_other</th>\n",
              "      <th>session_tag_cheating</th>\n",
              "      <th>session_tag_inappropriate</th>\n",
              "      <th>session_tag_other_subject</th>\n",
              "      <th>avg_words_tutor</th>\n",
              "      <th>n_words_tutor</th>\n",
              "      <th>n_msg_tutor</th>\n",
              "      <th>avg_words_student</th>\n",
              "      <th>n_words_student</th>\n",
              "      <th>n_msg_student</th>\n",
              "      <th>student_rating_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18172</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.923077</td>\n",
              "      <td>246.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.142857</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8593</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.666667</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43182</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>295.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>4.545455</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94301</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.651934</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>4.397727</td>\n",
              "      <td>387.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>181</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.791667</td>\n",
              "      <td>235.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7.529412</td>\n",
              "      <td>128.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tutor_id  tutor_age  ...  n_msg_student  student_rating_cat\n",
              "0     18172         52  ...            7.0                   1\n",
              "1      8593         52  ...            6.0                   0\n",
              "2     43182         42  ...           11.0                   1\n",
              "3     94301         21  ...           88.0                   1\n",
              "4       181         52  ...           17.0                   1\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O76sbPMKt366",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# División entre instancias y etiquetas\n",
        "X, y = datos_curados.iloc[:, 1:], datos_curados.student_rating_cat\n",
        "\n",
        "# división entre entrenamiento y evaluación\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRYGmLtLue47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verificar con mis compañeros\n",
        "escalado = StandardScaler()\n",
        "escalado.fit(X_train)\n",
        "X_train = escalado.transform(X_train)\n",
        "X_test  = escalado.transform(X_test)  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMOdo100yFOO",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhYjXvFjtdwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "26c79509-1ea7-4d41-aed0-9fbd6583586b"
      },
      "source": [
        "# elijo el modelo del gradiente descendente\n",
        "modelGD = SGDClassifier(random_state=0)\n",
        "\n",
        "print('Parámetros utilizados: \\n', np.array(list(modelGD.get_params(deep=False).items())))\n",
        "#modelGD.get_params  "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parámetros utilizados: \n",
            " [['alpha' 0.0001]\n",
            " ['average' False]\n",
            " ['class_weight' None]\n",
            " ['early_stopping' False]\n",
            " ['epsilon' 0.1]\n",
            " ['eta0' 0.0]\n",
            " ['fit_intercept' True]\n",
            " ['l1_ratio' 0.15]\n",
            " ['learning_rate' 'optimal']\n",
            " ['loss' 'hinge']\n",
            " ['max_iter' 1000]\n",
            " ['n_iter_no_change' 5]\n",
            " ['n_jobs' None]\n",
            " ['penalty' 'l2']\n",
            " ['power_t' 0.5]\n",
            " ['random_state' 0]\n",
            " ['shuffle' True]\n",
            " ['tol' 0.001]\n",
            " ['validation_fraction' 0.1]\n",
            " ['verbose' 0]\n",
            " ['warm_start' False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-zQTonPtxPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entrenamiento\n",
        "modelGD.fit(X_train, y_train);"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNL6GEgwu5JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicción \n",
        "y_train_predictGD = modelGD.predict(X_train)\n",
        "y_test_predictGD = modelGD.predict (X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xSsMEwxfla",
        "colab_type": "text"
      },
      "source": [
        "**Métricas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvaM9b4ru-WY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "79278f64-096b-4f7e-9bcb-92322fb35baa"
      },
      "source": [
        "# Calculamos las métricas más comunes (Ac: accuracy, Pr:precisión, Re: recall, F1, CM:matriz de confusión)\n",
        "print('Resultados obtenidos en Entrenamiento')\n",
        "print('------------------------------------------------------------')\n",
        "print(classification_report(y_train, y_train_predictGD, digits=3))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados obtenidos en Entrenamiento\n",
            "------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      1.000     1.000     1.000      2041\n",
            "           1      1.000     1.000     1.000      7691\n",
            "\n",
            "    accuracy                          1.000      9732\n",
            "   macro avg      1.000     1.000     1.000      9732\n",
            "weighted avg      1.000     1.000     1.000      9732\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx8yiy9NwxvU",
        "colab_type": "text"
      },
      "source": [
        "**Matriz de confusión**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E4Zp8IWvG1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "29856f5e-71d3-4f72-d5d9-3e22c594e463"
      },
      "source": [
        "# cálculo\n",
        "print('matriz de confusión')\n",
        "mtx_confusion_trainGD= confusion_matrix(y_train, y_train_predictGD)\n",
        "print(mtx_confusion_trainGD)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matriz de confusión\n",
            "[[2041    0]\n",
            " [   0 7691]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pERPFAuw963",
        "colab_type": "text"
      },
      "source": [
        "**Gráfico**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VROXXEKkv1LE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "a6956518-b65f-414f-8902-25cb875a165e"
      },
      "source": [
        "# graficamos la matriz de confusión con datos de prueba\n",
        "plt.figure(figsize=(10,6))  \n",
        "plt.clf()\n",
        "plt.imshow(mtx_confusion_trainGD, interpolation='nearest', cmap=plt.cm.BuPu)#Orangescmap=plt.mtx_confusion_test.Wistia from matplotlib.colors import ListedColormap\n",
        "classNames = ['Negativo','Positivo']\n",
        "plt.title('Matriz de confusión con datos de Train')\n",
        "plt.ylabel('Valores Reales')\n",
        "plt.xlabel('Valores Predichos')\n",
        "tick_marks = np.arange(len(classNames))\n",
        "plt.xticks(tick_marks, classNames, rotation=45)\n",
        "plt.yticks(tick_marks, classNames)\n",
        "s = [['TN','FP'], ['FN', 'TP']]\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i, str(s[i][j])+\" = \"+str(mtx_confusion_trainGD[i][j]))\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNkH14LSwFc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e6bc5a90-7149-45b5-fb72-e8f83dc04358"
      },
      "source": [
        "# Imrpimimos las métricas más comunes (Ac: accuracy, Pr:precisión, Re: recall, F1, CM:matriz de confusión)\n",
        "print('Resultados obtenidos en Prueba')\n",
        "print('------------------------------------------------------------')\n",
        "print(classification_report(y_test, y_test_predictGD, digits=4))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados obtenidos en Prueba\n",
            "------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000       473\n",
            "           1     1.0000    1.0000    1.0000      1960\n",
            "\n",
            "    accuracy                         1.0000      2433\n",
            "   macro avg     1.0000    1.0000    1.0000      2433\n",
            "weighted avg     1.0000    1.0000    1.0000      2433\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTeSOZDOwu13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ff2691a3-c1af-4f06-f66a-adfd176316ec"
      },
      "source": [
        "# cálculo\n",
        "print('matriz de confusión')\n",
        "mtx_confusion_testGD= confusion_matrix(y_test, y_test_predictGD)\n",
        "print(mtx_confusion_testGD)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matriz de confusión\n",
            "[[ 473    0]\n",
            " [   0 1960]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q047GUkrxkhP",
        "colab_type": "text"
      },
      "source": [
        "**Gráfico**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSa74zEwTfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "6bbc8278-5edf-450b-85ca-ef9ce254530c"
      },
      "source": [
        "# graficamos la matriz de confusión con datos de prueba\n",
        "plt.figure(figsize=(10,6))  \n",
        "plt.clf()\n",
        "plt.imshow(mtx_confusion_testGD, interpolation='nearest', cmap=plt.cm.BuPu)#Orangescmap=plt.mtx_confusion_test.Wistia from matplotlib.colors import ListedColormap\n",
        "classNames = ['Negativo','Positivo']\n",
        "plt.title('Matriz de confusión con datos de Test')\n",
        "plt.ylabel('Valores Reales')\n",
        "plt.xlabel('Valores Predichos')\n",
        "tick_marks = np.arange(len(classNames))\n",
        "plt.xticks(tick_marks, classNames, rotation=45)\n",
        "plt.yticks(tick_marks, classNames)\n",
        "s = [['TN','FP'], ['FN', 'TP']]\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i, str(s[i][j])+\" = \"+str(mtx_confusion_testGD[i][j]))\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEyOYFflyNpI",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio 2.2: Ajuste de Hiperparámetros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BFF5pTcx3Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelGD2 = SGDClassifier(random_state=0)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zATQOWn2KRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid_GD2 = {\n",
        "  'learning_rate': ['optimal','constant', 'adaptive'],  #diferents opciones de tasa de entrenamiento\n",
        "  'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'], #diferentes opciones de función de costo\n",
        "  'l1_ratio': list(np.linspace(0, 1, 11))+[0.15], # diferentes opciones de tasas de regularización\n",
        "  'alpha': np.logspace(-5, 0, 6),\n",
        "  'eta0': np.logspace(-5, 0, 6)\n",
        "} # se podrían agregar nuevos parámetros para buscar mejores modelos, estas opciones no brindan los mejores resultados"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GemveoBm2PiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "817ddd57-f971-4e45-da72-44b7e74b9132"
      },
      "source": [
        "from sklearn.model_selection import ParameterSampler\n",
        "\n",
        "for params in ParameterSampler(param_grid_GD2, 4, random_state=0):\n",
        "    print(params)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.15, 'eta0': 1e-05, 'alpha': 0.01}\n",
            "{'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.1, 'eta0': 1e-05, 'alpha': 0.01}\n",
            "{'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 1.0, 'alpha': 0.0001}\n",
            "{'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.1, 'alpha': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkjwoOak2lsD",
        "colab_type": "text"
      },
      "source": [
        "**Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNVKY0sG2U5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelGD2.fit(X_train, y_train);"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HMuFzT02p4A",
        "colab_type": "text"
      },
      "source": [
        "**Predicción**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5gQrEV82fsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_predictGD2 = modelGD2.predict(X_train)\n",
        "y_test_predictGD2 = modelGD2.predict (X_test)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR3fQP_o3Ijc",
        "colab_type": "text"
      },
      "source": [
        "**Utilizo gridsearchCV para probar las diferentes combinaciones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZpgYk4S29Vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e32f5b7e-88f3-4b69-9e5c-82f07a048eac"
      },
      "source": [
        "grid_gd2 = GridSearchCV(modelGD2, param_grid_GD2, cv=5, scoring=['accuracy'], refit= False) #sino ponfo refit en false genera error\n",
        "grid_gd2.fit(X_train, y_train) \n",
        "# probar con refit= True\n",
        "# probar agregando otros scoring como precision, recall y f1\n",
        "# considerar aumentar el número máximo de iteraciones para mejorar el fit."
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                     class_weight=None, early_stopping=False,\n",
              "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                                     l1_ratio=0.15, learning_rate='optimal',\n",
              "                                     loss='hinge', max_iter=1000,\n",
              "                                     n_iter_no_change=5, n_jobs=None,\n",
              "                                     penalty='l2', power_t=0.5, random_state=0,\n",
              "                                     shuffle=True, tol=0.001,\n",
              "                                     validation_fraction=0.1, ver...\n",
              "                         'eta0': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n",
              "                         'l1_ratio': [0.0, 0.1, 0.2, 0.30000000000000004, 0.4,\n",
              "                                      0.5, 0.6000000000000001,\n",
              "                                      0.7000000000000001, 0.8, 0.9, 1.0, 0.15],\n",
              "                         'learning_rate': ['optimal', 'constant', 'adaptive'],\n",
              "                         'loss': ['hinge', 'log', 'modified_huber',\n",
              "                                  'squared_hinge']},\n",
              "             pre_dispatch='2*n_jobs', refit=False, return_train_score=False,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu_pxFuxKKzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "929f24ed-34ab-4790-9985-07427ddae97e"
      },
      "source": [
        "# prueba con refit en True y otro scoring\n",
        " grid_gd3 = GridSearchCV(modelGD2, param_grid_GD2, cv=5, scoring=['accuracy','precision'], refit= False)\n",
        " grid_gd3.fit(X_train, y_train) "
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-03a7b36a70fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prueba con refit en True y otro scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgrid_gd3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelGD2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid_GD2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid_gd2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    709\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[0;32m--> 550\u001b[0;31m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         if (self.tol is not None and self.tol > -np.inf\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    508\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                              max_iter=max_iter)\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[1;32m    566\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m                                               \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                                               random_state=self.random_state)\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[0;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[1;32m    407\u001b[0m                            \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                            \u001b[0mlearning_rate_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                            est.power_t, est.t_, intercept_decay)\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy-UnI293h47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A los resultados lo guardamos como dataframe\n",
        "grid_gd2_df = pd.DataFrame(grid_gd2.cv_results_)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNKUQ0bI9ToS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "861a42a2-ca10-4f4b-e08c-002ab68a4f02"
      },
      "source": [
        "grid_gd2_df.columns"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
              "       'param_alpha', 'param_eta0', 'param_l1_ratio', 'param_learning_rate',\n",
              "       'param_loss', 'params', 'split0_test_accuracy', 'split1_test_accuracy',\n",
              "       'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy',\n",
              "       'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtrzYYVc9WFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3d56f55-7faf-4453-a522-99c252e8cd3c"
      },
      "source": [
        "grid_gd2_df\n",
        "# grid_gd2_df.shape: dataframe de 5184 filas y 18 columnas"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>param_eta0</th>\n",
              "      <th>param_l1_ratio</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_loss</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_accuracy</th>\n",
              "      <th>split1_test_accuracy</th>\n",
              "      <th>split2_test_accuracy</th>\n",
              "      <th>split3_test_accuracy</th>\n",
              "      <th>split4_test_accuracy</th>\n",
              "      <th>mean_test_accuracy</th>\n",
              "      <th>std_test_accuracy</th>\n",
              "      <th>rank_test_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.010503</td>\n",
              "      <td>0.001341</td>\n",
              "      <td>0.000948</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>optimal</td>\n",
              "      <td>hinge</td>\n",
              "      <td>{'alpha': 1e-05, 'eta0': 1e-05, 'l1_ratio': 0....</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.019174</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>optimal</td>\n",
              "      <td>log</td>\n",
              "      <td>{'alpha': 1e-05, 'eta0': 1e-05, 'l1_ratio': 0....</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994347</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998869</td>\n",
              "      <td>0.002261</td>\n",
              "      <td>3973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.010803</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>optimal</td>\n",
              "      <td>modified_huber</td>\n",
              "      <td>{'alpha': 1e-05, 'eta0': 1e-05, 'l1_ratio': 0....</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>0.999692</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.000894</td>\n",
              "      <td>0.000934</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>optimal</td>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>{'alpha': 1e-05, 'eta0': 1e-05, 'l1_ratio': 0....</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>0.998972</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>0.000325</td>\n",
              "      <td>3841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.030934</td>\n",
              "      <td>0.001522</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>constant</td>\n",
              "      <td>hinge</td>\n",
              "      <td>{'alpha': 1e-05, 'eta0': 1e-05, 'l1_ratio': 0....</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5179</th>\n",
              "      <td>0.023044</td>\n",
              "      <td>0.005081</td>\n",
              "      <td>0.001094</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>constant</td>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>{'alpha': 1.0, 'eta0': 1.0, 'l1_ratio': 0.15, ...</td>\n",
              "      <td>0.789933</td>\n",
              "      <td>0.209553</td>\n",
              "      <td>0.790339</td>\n",
              "      <td>0.790339</td>\n",
              "      <td>0.790339</td>\n",
              "      <td>0.674101</td>\n",
              "      <td>0.232274</td>\n",
              "      <td>5161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5180</th>\n",
              "      <td>0.082771</td>\n",
              "      <td>0.001973</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>hinge</td>\n",
              "      <td>{'alpha': 1.0, 'eta0': 1.0, 'l1_ratio': 0.15, ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5181</th>\n",
              "      <td>0.138225</td>\n",
              "      <td>0.007386</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>log</td>\n",
              "      <td>{'alpha': 1.0, 'eta0': 1.0, 'l1_ratio': 0.15, ...</td>\n",
              "      <td>0.794042</td>\n",
              "      <td>0.794042</td>\n",
              "      <td>0.791367</td>\n",
              "      <td>0.790339</td>\n",
              "      <td>0.792909</td>\n",
              "      <td>0.792540</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>5077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5182</th>\n",
              "      <td>0.095223</td>\n",
              "      <td>0.011959</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>modified_huber</td>\n",
              "      <td>{'alpha': 1.0, 'eta0': 1.0, 'l1_ratio': 0.15, ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999897</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>2797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5183</th>\n",
              "      <td>0.101898</td>\n",
              "      <td>0.010730</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>{'alpha': 1.0, 'eta0': 1.0, 'l1_ratio': 0.15, ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999486</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999897</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>2797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5184 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mean_fit_time  std_fit_time  ...  std_test_accuracy  rank_test_accuracy\n",
              "0          0.010503      0.001341  ...           0.000000                   1\n",
              "1          0.019174      0.002000  ...           0.002261                3973\n",
              "2          0.010803      0.000977  ...           0.000252                3457\n",
              "3          0.011917      0.000894  ...           0.000325                3841\n",
              "4          0.030934      0.001522  ...           0.000000                   1\n",
              "...             ...           ...  ...                ...                 ...\n",
              "5179       0.023044      0.005081  ...           0.232274                5161\n",
              "5180       0.082771      0.001973  ...           0.000000                   1\n",
              "5181       0.138225      0.007386  ...           0.001474                5077\n",
              "5182       0.095223      0.011959  ...           0.000206                2797\n",
              "5183       0.101898      0.010730  ...           0.000206                2797\n",
              "\n",
              "[5184 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkJlqOoq9t87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seleccionamos las columnas que serán útiles para elegir las configuraciones con mejor performance\n",
        "gd2_df = grid_gd2_df [['param_alpha', 'param_eta0', 'param_l1_ratio', 'param_learning_rate',\n",
        "       'param_loss', 'params','mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy']]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj5dXeOT-CXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e448a481-a255-45d1-8301-782c1f2ee6a1"
      },
      "source": [
        "# Selecciono aquel con con menor valor en 'rank_test_accuracy'\n",
        "\n",
        "gd2_con_accuracy= gd2_df.loc[gd2_df.rank_test_accuracy.idxmin()]\n",
        "\n",
        "print('---------------------------------------------------------------------------------------------------------'\n",
        "      '\\n Puntaje y parámetros correspondiente al modelo con mejor performance según:'\n",
        "      '\\n ------------------------------------------------------------------------------------------------------'\n",
        "      '\\n Accuracy  {:.4f}:{}\\n'.format(\n",
        "      gd2_con_accuracy.mean_test_accuracy, gd2_con_accuracy.params),\n",
        "      '\\n------------------------------------------------------------------------------------------------------')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------------\n",
            " Puntaje y parámetros correspondiente al modelo con mejor performance según:\n",
            " ------------------------------------------------------------------------------------------------------\n",
            " Accuracy  1.0000:{'alpha': 1e-05, 'eta0': 1e-05, 'l1_ratio': 0.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
            " \n",
            "------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31_XI_zS-K5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradiente_descendente_ac = SGDClassifier(**gd2_con_accuracy.params, random_state=0)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmi0XEaI-hFO",
        "colab_type": "text"
      },
      "source": [
        "**Entrenamiento con los parámetros del mejor puntaje respecto a accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gnjHQ79dwRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "cb3d2ebc-0147-4709-b4f8-a910429cbb2a"
      },
      "source": [
        "gradiente_descendente_ac.fit(X_train, y_train)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=1e-05, fit_intercept=True,\n",
              "              l1_ratio=0.0, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW_SVfmY_Gkp",
        "colab_type": "text"
      },
      "source": [
        "**Predicción**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TiypDLz_F8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred_gradiente_desc = gradiente_descendente_ac.predict(X_train)\n",
        "y_test_pred_gradiente_desc = gradiente_descendente_ac.predict(X_test)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8qwLQWAB3mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8596c3ab-3021-4449-e587-100ba755bc06"
      },
      "source": [
        "# Calculamos las métricas más comunes (Ac: accuracy, Pr:precisión, Re: recall, F1, CM:matriz de confusión)\n",
        "print('Resultados obtenidos en Prueba')\n",
        "print('------------------------------------------------------------')\n",
        "print(classification_report(y_train, y_train_pred_gradiente_desc, digits=4))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados obtenidos en Prueba\n",
            "------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000      2041\n",
            "           1     1.0000    1.0000    1.0000      7691\n",
            "\n",
            "    accuracy                         1.0000      9732\n",
            "   macro avg     1.0000    1.0000    1.0000      9732\n",
            "weighted avg     1.0000    1.0000    1.0000      9732\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vQnQnxmgfDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "662ca913-0fb5-4bb3-8539-e268c8c548a2"
      },
      "source": [
        "# Calculamos las métricas más comunes (Ac: accuracy, Pr:precisión, Re: recall, F1, CM:matriz de confusión)\n",
        "print('Resultados obtenidos en Prueba')\n",
        "print('------------------------------------------------------------')\n",
        "print(classification_report(y_test, y_test_pred_gradiente_desc, digits=4))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados obtenidos en Prueba\n",
            "------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000       473\n",
            "           1     1.0000    1.0000    1.0000      1960\n",
            "\n",
            "    accuracy                         1.0000      2433\n",
            "   macro avg     1.0000    1.0000    1.0000      2433\n",
            "weighted avg     1.0000    1.0000    1.0000      2433\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP8nck9uCs3I",
        "colab_type": "text"
      },
      "source": [
        "No se obtuvieron mejores valores que con los parámetros por defecto así que deberíamos agregar otros scorings entre los prarámetros seleccionados y refit a True."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osYeHR0ZDGoT",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio 3: Árboles de Decisión**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgLFX6oFEV33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "a8928264-cab2-44d5-9c2d-64d2b59d2754"
      },
      "source": [
        "arbol_decision = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "print('Parámetros utilizados: \\n', np.array(list(arbol_decision.get_params(deep=False).items())))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parámetros utilizados: \n",
            " [['ccp_alpha' 0.0]\n",
            " ['class_weight' None]\n",
            " ['criterion' 'gini']\n",
            " ['max_depth' None]\n",
            " ['max_features' None]\n",
            " ['max_leaf_nodes' None]\n",
            " ['min_impurity_decrease' 0.0]\n",
            " ['min_impurity_split' None]\n",
            " ['min_samples_leaf' 1]\n",
            " ['min_samples_split' 2]\n",
            " ['min_weight_fraction_leaf' 0.0]\n",
            " ['presort' 'deprecated']\n",
            " ['random_state' 0]\n",
            " ['splitter' 'best']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM6MnGTDEwZE",
        "colab_type": "text"
      },
      "source": [
        "**Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA-rJ6UEEv2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d79542ba-0538-4c05-ba50-18edb72729e7"
      },
      "source": [
        "arbol_decision.fit(X_train, y_train)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJeFiYvDE2Ih",
        "colab_type": "text"
      },
      "source": [
        "**Predicción**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-vPnWY4FBeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred_arbolD = arbol_decision.predict(X_train)\n",
        "y_test_pred_arbolD  = arbol_decision.predict(X_test)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peIX7f5EFN3_",
        "colab_type": "text"
      },
      "source": [
        "**Valores máximos de profundidad y cantidad de hojas máxima**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5f4wOdVFOSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ad937e5d-bed5-4340-8884-2a0090d3b383"
      },
      "source": [
        "print('Profundidad máxima del árbol:', arbol_decision.get_depth())\n",
        "print('Cantidad máxima de hojas:', arbol_decision.get_n_leaves())"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Profundidad máxima del árbol: 1\n",
            "Cantidad máxima de hojas: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5mnhDCWFzFB",
        "colab_type": "text"
      },
      "source": [
        "**Gráficos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLVghIQsF03s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "f418ddce-37a6-49b6-bd7f-11d1df9fb03f"
      },
      "source": [
        "# árbol sin especificar el nro. de ramas\n",
        "plt.figure(figsize=(17,10))\n",
        "plot_tree(arbol_decision, impurity=False, fontsize=11, filled=True, label='root')  #filled=True,\n",
        "plt.show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1224x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz-ETUiETAnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "df434cc6-612c-4d5e-db14-3c6a10e337b9"
      },
      "source": [
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amn30RXISUv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "e0857608-29b0-4650-9cd4-8d11cb0db5df"
      },
      "source": [
        "# otra opción de gráficos\n",
        "import graphviz\n",
        "from sklearn import tree\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn import datasets\n",
        "from sklearn import model_selection\n",
        "\n",
        "dot_data = tree.export_graphviz(arbol_decision, out_file=None, \n",
        "                         #feature_names=datos_curados.feature_names,  \n",
        "                         #class_names= datos_curados.target_names,  \n",
        "                         filled=True, rounded=True,  \n",
        "                         special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fb1c7488b38>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"274pt\" height=\"161pt\"\n viewBox=\"0.00 0.00 274.00 161.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 157)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-157 270,-157 270,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#6eb7ec\" stroke=\"#000000\" d=\"M195.5,-153C195.5,-153 70.5,-153 70.5,-153 64.5,-153 58.5,-147 58.5,-141 58.5,-141 58.5,-101 58.5,-101 58.5,-95 64.5,-89 70.5,-89 70.5,-89 195.5,-89 195.5,-89 201.5,-89 207.5,-95 207.5,-101 207.5,-101 207.5,-141 207.5,-141 207.5,-147 201.5,-153 195.5,-153\"/>\n<text text-anchor=\"start\" x=\"92.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X</text>\n<text text-anchor=\"start\" x=\"102.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" baseline-shift=\"sub\" font-size=\"14.00\" fill=\"#000000\">18</text>\n<text text-anchor=\"start\" x=\"116.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\"> ≤ &#45;0.713</text>\n<text text-anchor=\"start\" x=\"95\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.331</text>\n<text text-anchor=\"start\" x=\"81\" y=\"-110.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 9732</text>\n<text text-anchor=\"start\" x=\"66.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2041, 7691]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M112,-53C112,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 112,0 112,0 118,0 124,-6 124,-12 124,-12 124,-41 124,-41 124,-47 118,-53 112,-53\"/>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"10\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2041</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2041, 0]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M108.7644,-88.7428C102.1209,-79.9004 94.8903,-70.2765 88.1449,-61.2985\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"90.9224,-59.1684 82.1173,-53.2759 85.3259,-63.3732 90.9224,-59.1684\"/>\n<text text-anchor=\"middle\" x=\"78.6027\" y=\"-74.3276\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M254,-53C254,-53 154,-53 154,-53 148,-53 142,-47 142,-41 142,-41 142,-12 142,-12 142,-6 148,0 154,0 154,0 254,0 254,0 260,0 266,-6 266,-12 266,-12 266,-41 266,-41 266,-47 260,-53 254,-53\"/>\n<text text-anchor=\"start\" x=\"174.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"152\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7691</text>\n<text text-anchor=\"start\" x=\"150\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 7691]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.2356,-88.7428C163.8791,-79.9004 171.1097,-70.2765 177.8551,-61.2985\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.6741,-63.3732 183.8827,-53.2759 175.0776,-59.1684 180.6741,-63.3732\"/>\n<text text-anchor=\"middle\" x=\"187.3973\" y=\"-74.3276\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sty-Fz8TF9Bm",
        "colab_type": "text"
      },
      "source": [
        "**Métricas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjPMvYZQGKGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f7206e6a-9012-437e-a16c-98dd4f9a9054"
      },
      "source": [
        "# Calculamos las métricas más comunes (Ac: accuracy, Pr:precisión, Re: recall, F1, CM:matriz de confusión)\n",
        "print('Resultados obtenidos en Entrenamiento')\n",
        "print('------------------------------------------------------------')\n",
        "print(classification_report(y_train, y_train_pred_arbolD, digits=3))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados obtenidos en Entrenamiento\n",
            "------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      1.000     1.000     1.000      2041\n",
            "           1      1.000     1.000     1.000      7691\n",
            "\n",
            "    accuracy                          1.000      9732\n",
            "   macro avg      1.000     1.000     1.000      9732\n",
            "weighted avg      1.000     1.000     1.000      9732\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuY9XB_VGZ-V",
        "colab_type": "text"
      },
      "source": [
        "**Matriz de confusión**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLjnVxR5GJ_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "59dbabb6-88da-4071-8bb6-16d309eefc79"
      },
      "source": [
        "print('Matriz de confusión con datos de entrenamiento')\n",
        "mtx_confusion_train_arbolD= confusion_matrix(y_train, y_train_pred_arbolD)\n",
        "print(mtx_confusion_train_arbolD)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz de confusión con datos de entrenamiento\n",
            "[[2041    0]\n",
            " [   0 7691]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbsa5K94G4rl",
        "colab_type": "text"
      },
      "source": [
        "**Gráfico**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgvcC7XxGq0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "10bdd884-8ded-4028-e2a0-71daa83eab11"
      },
      "source": [
        "# graficamos la matriz de confusión con datos de train o entrenamiento\n",
        "plt.figure(figsize=(10,6))  \n",
        "plt.clf()\n",
        "plt.imshow(mtx_confusion_train_arbolD, interpolation='nearest', cmap=plt.cm.BuPu)#Orangescmap=plt.mtx_confusion_test.Wistia from matplotlib.colors import ListedColormap\n",
        "classNames = ['Negativo','Positivo']\n",
        "plt.title('Matriz de confusión con datos de entrenamiento')\n",
        "plt.ylabel('Valores Reales')\n",
        "plt.xlabel('Valores Predichos')\n",
        "tick_marks = np.arange(len(classNames))\n",
        "plt.xticks(tick_marks, classNames, rotation=45)\n",
        "plt.yticks(tick_marks, classNames)\n",
        "s = [['TN','FP'], ['FN', 'TP']]\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i, str(s[i][j])+\" = \"+str(mtx_confusion_train_arbolD[i][j]))\n",
        "plt.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUHSpKrJG7gS",
        "colab_type": "text"
      },
      "source": [
        "Teniendo en cuenta los resultados obtenidos aplicando el algoritmo del gradiente descendiente y árboles de decisión, en ambos casos con parámetros por defecto, se evidencian resultados similares por lo ninguno ofrece mejoras de performance sobre el otro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsGIHv1SWl1j",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 3.2: Ajuste de Hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNTdgh0pW5Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arbol_decision_con_param = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlPf5QP-YhQq",
        "colab_type": "text"
      },
      "source": [
        "**Opciones de parámetros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kciF1wg7Yc8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_arbol_decision = [\n",
        "  {'splitter': ['best'],\n",
        "          'criterion': ['gini', 'entropy'],\n",
        "          'max_depth': list(np.arange(4,20,2)),\n",
        "          'min_samples_leaf': np.arange(1,10)\n",
        "          },\n",
        "  {'splitter': ['random'],\n",
        "          'criterion': ['gini', 'entropy'],\n",
        "          'max_depth': list(np.arange(4,20,2)),\n",
        "          'min_samples_leaf': np.arange(1,10)\n",
        "          }\n",
        "]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bAPW0KEYoXs",
        "colab_type": "text"
      },
      "source": [
        "**Utilizamos grid-search con 5-fold cross-validation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkOgH5Q2Yzny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_ad = GridSearchCV(arbol_decision_con_param, param_arbol_decision, cv=5, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False)\n",
        "grid_ad.fit(X_train, y_train);"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-9uukRY58d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# los resultados de la búsqueda lo guardamos como dataframe\n",
        "arbol_decision_con_param_df = pd.DataFrame(grid_ad.cv_results_)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e05fGYvJZBDd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f718fac-a58c-45d9-920a-94ad2305e24a"
      },
      "source": [
        "arbol_decision_con_param_df  # 288 filas por 41"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_min_samples_leaf</th>\n",
              "      <th>param_splitter</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_accuracy</th>\n",
              "      <th>split1_test_accuracy</th>\n",
              "      <th>split2_test_accuracy</th>\n",
              "      <th>split3_test_accuracy</th>\n",
              "      <th>split4_test_accuracy</th>\n",
              "      <th>mean_test_accuracy</th>\n",
              "      <th>std_test_accuracy</th>\n",
              "      <th>rank_test_accuracy</th>\n",
              "      <th>split0_test_precision_weighted</th>\n",
              "      <th>split1_test_precision_weighted</th>\n",
              "      <th>split2_test_precision_weighted</th>\n",
              "      <th>split3_test_precision_weighted</th>\n",
              "      <th>split4_test_precision_weighted</th>\n",
              "      <th>mean_test_precision_weighted</th>\n",
              "      <th>std_test_precision_weighted</th>\n",
              "      <th>rank_test_precision_weighted</th>\n",
              "      <th>split0_test_recall_weighted</th>\n",
              "      <th>split1_test_recall_weighted</th>\n",
              "      <th>split2_test_recall_weighted</th>\n",
              "      <th>split3_test_recall_weighted</th>\n",
              "      <th>split4_test_recall_weighted</th>\n",
              "      <th>mean_test_recall_weighted</th>\n",
              "      <th>std_test_recall_weighted</th>\n",
              "      <th>rank_test_recall_weighted</th>\n",
              "      <th>split0_test_f1_weighted</th>\n",
              "      <th>split1_test_f1_weighted</th>\n",
              "      <th>split2_test_f1_weighted</th>\n",
              "      <th>split3_test_f1_weighted</th>\n",
              "      <th>split4_test_f1_weighted</th>\n",
              "      <th>mean_test_f1_weighted</th>\n",
              "      <th>std_test_f1_weighted</th>\n",
              "      <th>rank_test_f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007729</td>\n",
              "      <td>0.001393</td>\n",
              "      <td>0.004735</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>gini</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>best</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.006988</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.005032</td>\n",
              "      <td>0.001043</td>\n",
              "      <td>gini</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>best</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.006724</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.004446</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>gini</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>best</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.006913</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.004560</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>gini</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>best</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.006695</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.004418</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>gini</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>best</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>0.003064</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.004392</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>entropy</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>random</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 18, 'min...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.004372</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>entropy</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>random</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 18, 'min...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>0.003079</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.004375</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>entropy</td>\n",
              "      <td>18</td>\n",
              "      <td>7</td>\n",
              "      <td>random</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 18, 'min...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>0.002981</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.004397</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>entropy</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>random</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 18, 'min...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>0.003008</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.004372</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>entropy</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>random</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 18, 'min...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>288 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_fit_time  std_fit_time  ...  std_test_f1_weighted  rank_test_f1_weighted\n",
              "0         0.007729      0.001393  ...                   0.0                      1\n",
              "1         0.006988      0.000607  ...                   0.0                      1\n",
              "2         0.006724      0.000032  ...                   0.0                      1\n",
              "3         0.006913      0.000099  ...                   0.0                      1\n",
              "4         0.006695      0.000025  ...                   0.0                      1\n",
              "..             ...           ...  ...                   ...                    ...\n",
              "283       0.003064      0.000031  ...                   0.0                      1\n",
              "284       0.003059      0.000054  ...                   0.0                      1\n",
              "285       0.003079      0.000084  ...                   0.0                      1\n",
              "286       0.002981      0.000033  ...                   0.0                      1\n",
              "287       0.003008      0.000059  ...                   0.0                      1\n",
              "\n",
              "[288 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4zIr6H-ZGju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seleccionamos las columnas que serán útiles para elegir las configuraciones con mejor performance\n",
        "arbol_decision_con_param_df = arbol_decision_con_param_df[['param_criterion', 'param_max_depth',\n",
        "                              'param_min_samples_leaf', 'param_splitter', 'params', 'mean_test_accuracy', \n",
        "                              'std_test_accuracy', 'rank_test_accuracy','mean_test_precision_weighted','std_test_precision_weighted',\n",
        "                              'rank_test_precision_weighted', 'mean_test_recall_weighted','std_test_recall_weighted',\n",
        "                               'rank_test_recall_weighted', 'mean_test_f1_weighted', 'std_test_f1_weighted', 'rank_test_f1_weighted']]"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cRS3xggZSgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "848436cc-d19d-4a5b-d99c-669dabc4d33c"
      },
      "source": [
        "# Seleccionamos los que tienen mejores valores para acurracy, precision, recall y f1.\n",
        "\n",
        "arbol_decision_según_accuracy = arbol_decision_con_param_df.loc[arbol_decision_con_param_df.rank_test_accuracy.idxmin()]\n",
        "arbol_decision_según_precision = arbol_decision_con_param_df.loc[arbol_decision_con_param_df.rank_test_precision_weighted.idxmin()]\n",
        "arbol_decision_según_recall = arbol_decision_con_param_df.loc[arbol_decision_con_param_df.rank_test_recall_weighted.idxmin()]\n",
        "arbol_decision_según_f1 = arbol_decision_con_param_df.loc[arbol_decision_con_param_df.rank_test_f1_weighted.idxmin()]\n",
        "#\n",
        "print('-------------------------------------------------------------------------------'\n",
        "      '\\n Puntaje y parámetros correspondiente a los modelos con mejor performance según:'\n",
        "      '\\n ------------------------------------------------------------------------------'\n",
        "      '\\n Accuracy  {:.4f}: {}\\n Precision {:.4f}: {}\\n Recall    {:.4f}: {}'\n",
        "      '\\n F1-Score  {:.4f}: {}\\n'.format(\n",
        "          arbol_decision_según_accuracy.mean_test_accuracy, arbol_decision_según_accuracy.params,\n",
        "          arbol_decision_según_precision.mean_test_precision_weighted, arbol_decision_según_precision.params,\n",
        "          arbol_decision_según_recall.mean_test_recall_weighted, arbol_decision_según_recall.params,\n",
        "          arbol_decision_según_f1.mean_test_f1_weighted, arbol_decision_según_f1.params),\n",
        "      '-------------------------------------------------------------------------------')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------------\n",
            " Puntaje y parámetros correspondiente a los modelos con mejor performance según:\n",
            " ------------------------------------------------------------------------------\n",
            " Accuracy  1.0000: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'splitter': 'best'}\n",
            " Precision 1.0000: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'splitter': 'best'}\n",
            " Recall    1.0000: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'splitter': 'best'}\n",
            " F1-Score  1.0000: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'splitter': 'best'}\n",
            " -------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea0Y-9OlZc5A",
        "colab_type": "text"
      },
      "source": [
        "De acuerdo a los valores obtenidos en el punto anterior, ejecutamos el algoritmo 'DecisionTreeClassifier' utilizando los parámetros obtenidos para accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3SeNVCHZemG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arbol_decision_ac = DecisionTreeClassifier(**arbol_decision_según_accuracy.params, random_state=0)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk9S79vYZnAO",
        "colab_type": "text"
      },
      "source": [
        "**Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6lBwepPZkWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "08e1e50e-5f3d-4949-d34d-ccebd8c42ac4"
      },
      "source": [
        "arbol_decision_ac.fit(X_train, y_train)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D96SmAqSZsHi",
        "colab_type": "text"
      },
      "source": [
        "**Predicción**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi_6zinVZuqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred_arbol_ac = arbol_decision_ac.predict(X_train)\n",
        "y_test_pred_arbol_ac = arbol_decision_ac.predict(X_test)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-_5d-ZbZ2H-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "f48213a6-accf-48f0-80e9-58260d78073a"
      },
      "source": [
        "# arbol generado por el modelo 'arbol_decision_ac' con 4 ramas de profundidad\n",
        "plt.figure(figsize=(18,6))\n",
        "plot_tree(arbol_decision_ac, filled=True, max_depth= 4, fontsize=10, label='root')\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}